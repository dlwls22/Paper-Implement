{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPsUiCsGghh5UqgoHHwTVlf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Load Dataset"],"metadata":{"id":"y-UG8Sfpv5-d"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"HM3ljGfBoDY-","executionInfo":{"status":"ok","timestamp":1710922248838,"user_tz":-540,"elapsed":15819,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import gc\n","\n","from torchvision.datasets import FashionMNIST\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD, RMSprop, Adam\n","from torch import autograd\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm"]},{"cell_type":"code","source":["# Define the transforms\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5))\n","])\n","\n","# Load Dataset\n","train_dataset = FashionMNIST(root = './data', train = True, transform  = transform, download = True)\n","test_dataset = FashionMNIST(root = './data', train = True, transform = transform, download = True)"],"metadata":{"id":"IFAX87g3wK5w","executionInfo":{"status":"ok","timestamp":1710922249357,"user_tz":-540,"elapsed":523,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n","test_loader = DataLoader(test_dataset, batch_size = 128, shuffle = False)"],"metadata":{"id":"A9-qjuwBw1_-","executionInfo":{"status":"ok","timestamp":1710922249357,"user_tz":-540,"elapsed":10,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Mapping\n","mapping = {0: 'T-shirt/top',\n"," 1: 'Trouser',\n"," 2: 'Pullover',\n"," 3: 'Dress',\n"," 4: 'Coat',\n"," 5: 'Sandal',\n"," 6: 'Shirt',\n"," 7: 'Sneaker',\n"," 8: 'Bag',\n"," 9: 'Ankle boot'}"],"metadata":{"id":"2M-wg0BJxGZb","executionInfo":{"status":"ok","timestamp":1710922249358,"user_tz":-540,"elapsed":10,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Modeling"],"metadata":{"id":"9zNV5vLTxKmj"}},{"cell_type":"code","source":["class ConvNet(nn.Module):\n","  def __init__(self):\n","    super(ConvNet, self).__init__()\n","    self.seq = nn.Sequential(\n","        nn.Conv2d(in_channels = 1, out_channels = 48, kernel_size = (3, 3), padding = 'same'),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels = 48, out_channels = 32, kernel_size = (3, 3), padding = 'same'),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels = 32, out_channels = 16, kernel_size = (3, 3), padding = 'same'),\n","        nn.ReLU(),\n","        nn.Flatten(),\n","        nn.Linear(16 * 28 * 28, 10),\n","    )\n","\n","  def forward(self, x_batch):\n","    preds = self.seq(x_batch)\n","\n","    return preds\n","\n","conv_net = ConvNet()"],"metadata":{"id":"7-7QmRkBxJhB","executionInfo":{"status":"ok","timestamp":1710922249358,"user_tz":-540,"elapsed":10,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["conv_net"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imIIWOeJ0vEf","executionInfo":{"status":"ok","timestamp":1710922249358,"user_tz":-540,"elapsed":9,"user":{"displayName":"이진","userId":"07182137582732274273"}},"outputId":"1ca13b5f-d3b6-4665-9215-9ccdec92a539"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvNet(\n","  (seq): Sequential(\n","    (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","    (1): ReLU()\n","    (2): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","    (3): ReLU()\n","    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","    (5): ReLU()\n","    (6): Flatten(start_dim=1, end_dim=-1)\n","    (7): Linear(in_features=12544, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"eZF5GwRs1jkU"}},{"cell_type":"code","source":["def CalcValLoss(model, loss_func, val_loader):\n","  with torch.no_grad():\n","    val_losses = []\n","    for X_batch, Y_batch in val_loader:\n","      preds = model(X_batch)\n","      loss = loss_func(preds, Y_batch)\n","      val_losses.append(loss)\n","    print('Valid Categorical CrossEntropy : {:.4f}', format(torch.tensor(val_losses).mean()))\n","\n","def MakePredictions(model, loader):\n","  preds, Y_shuffled = [], []\n","  for X_batch, Y_batch in loader:\n","    preds.append(model(X_batch))\n","    Y_shuffled.append(Y_batch)\n","\n","  preds = torch.cat(preds).argmax(axis = -1)\n","  Y_shuffled = torch.act(Y_shuffled)\n","\n","  return Y_shuffled, preds\n","\n","def TrainModelInBatchesV1(model, loss_func, optimizer, train_loader, val_loader, epochs = 5):\n","  for i in range(epochs):\n","    losses = []\n","    for X_batch, Y_batch in tqdm(train_loader):\n","      preds = model(X_batch) # Network를 통해 순방향 전파하여 예측 수행\n","      loss = loss_func(preds, Y_batch) # Loss 계산\n","      losses.append(loss) # Loss 기록\n","      optimizer.zero_grad() # Gradients를 계산하기 전에 weight를 0으로 초기화\n","      loss.backward() # Gradients 계산\n","      optimizer.step() # Weight 업뎃\n","\n","    print('Train Categorical CrossEntropy : {:.4f}'.format(torch.tensor(losses).mean()))\n","    CalcValLoss(model, loss_func, val_loader)\n","\n","    Y_test_shuffled, test_preds = MakePredictions(model, val_loader)\n","    val_acc = accuracy_score(Y_test_shuffled, test_preds)\n","    print('Val ACC : {:.4f}'.format(val_acc))\n","    gc.collect()"],"metadata":{"id":"qAVaGH5E1h6y","executionInfo":{"status":"ok","timestamp":1710922249358,"user_tz":-540,"elapsed":8,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","epochs = 5\n","learning_rate = torch.tensor(1e-3)\n","\n","conv_net = ConvNet()\n","cel = nn.CrossEntropyLoss()\n","optimizer = Adam(params = conv_net.parameters(), lr = learning_rate)\n","\n","TrainModelInBatchesV1(conv_net, cel, optimizer, train_loader, test_loader, epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vbej6aIS4P8w","outputId":"d42081f0-2bd4-45e8-8aeb-7bc275201c8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 69%|██████▉   | 323/469 [02:41<00:46,  3.14it/s]"]}]},{"cell_type":"code","source":["# # 저장하기\n","# torch.save(conv_net, 'trained_model.pth')\n","\n","# # 불러오기\n","# conv_net = torch.load('trained_model.pth')"],"metadata":{"id":"yNlqw6mA4399"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Grad-CAM"],"metadata":{"id":"vPwXAlVI5NKs"}},{"cell_type":"markdown","source":["### 1. Capture Output of Last Convolution Layer"],"metadata":{"id":"v49vJVvR5SZt"}},{"cell_type":"code","source":["list(conv_net.children())[0]"],"metadata":{"id":"nxXpL7e75LiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LastConvLayerModel(nn.Module):\n","  def __init__(self):\n","    super(LastConvLayerModel, self).__init__()\n","    self.layers = list(list(conv_net.children())[0].children())\n","\n","  def forward(self, X_batch):\n","    x = self.layers[0](X_batch)\n","    conv_layer_output = None\n","    for i, layer in enumerate(self.layers[1:]):\n","      x = layer(x)\n","      if i == 3: # 3층 이후의 층\n","        self.conv_layer_output = x\n","\n","    return x"],"metadata":{"id":"kZkc28GM5amZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = test_dataset.data.resape(-1, 1, 28, 28).type(torch.float32)\n","Y_test = test_dataset.targets\n","\n","conv_model = LastConvLayerModel()\n","idx = np.random.choice(range(10000))\n","pred = conv_model(X_test[idx:idx+1])\n","\n","F.softmax(pred, dim=-1).argmax(), F.softmax(pred, dim=-1).max()"],"metadata":{"id":"lU4sPPD06zjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_model.conv_layer_output.shape"],"metadata":{"id":"WAQ_8cav7NY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Actual Target : {}'.format(mapping[Y_test[idx].item()]))\n","print('Predicted Target : {}'.format(mapping[pred.argmax(dim = -1).item()]))"],"metadata":{"id":"q4hqlos37NWs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Take Gradients of Last Convolution Layer Output with Respect to Prediction"],"metadata":{"id":"_zqusY007fpx"}},{"cell_type":"code","source":["grads = autograd.grad(pred[:, pred.argmax().item()], conv_model.conv_layer_output)\n","\n","grads[0].shape"],"metadata":{"id":"WJMNYvZY7pWZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Average Gradients"],"metadata":{"id":"SJn3TC_v74Xa"}},{"cell_type":"code","source":["pooled_grads = grads[0].mean((0, 2, 3))\n","\n","pooled_grads"],"metadata":{"id":"-EU4AHAF7pTu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Multiply Convolution Layer Output with Averaed Gradients"],"metadata":{"id":"Jrsm-7DT761t"}},{"cell_type":"code","source":["conv_output = conv_model.conv_layer_output.squeeze()\n","\n","conv_output = F.relu(conv_output)\n","\n","conv_output.shape"],"metadata":{"id":"G1RGFbl28FTo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(pooled_grads)):\n","  conv_output[i, :, :] *= pooled_grads[i]\n","\n","conv_output.shape"],"metadata":{"id":"9qhm7lAu8OZG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. Average Output at Channel axis to Create Heatmap"],"metadata":{"id":"ON22pcvU8Ovn"}},{"cell_type":"code","source":["heatmap = conv_output.mean(dim = 0).squeeze()\n","\n","# heatmap normalize\n","heatmap = F.relu(heatmap) / torch.max(heatmap)\n","\n","heatmap.shape"],"metadata":{"id":"1W2wl3Da8bwc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. Visualize Original Image and Heatmap"],"metadata":{"id":"LaFA6rmo8qGE"}},{"cell_type":"code","source":["def plot_actual_and_heatmap(idx, heatmap):\n","  cmap = matplotlib.cm.get_cmap('Reds')\n","\n","  fig = plt.figure(figsize = (10, 10))\n","  ax1 = fig.add_subplot(121)\n","  ax1.imshow(X_test[idx].numpy().squeeze(), cmap = 'gray')\n","  ax1.set_title('Actual')\n","  ax1.set_xticks([], []);ax1.set_yticks([], [])\n","\n","  ax2 = fig.add_subplot(122)\n","  ax2.imshow(heatmap, cmap = 'Reds')\n","  ax2.set_title('Gradients')\n","  ax2.set_xticks([], []);ax2.set_yticks([], [])\n","\n","plot_actual_and_heatmap(idx, heatmap.detach())"],"metadata":{"id":"BMo_55NC8t94"},"execution_count":null,"outputs":[]}]}
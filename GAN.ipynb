{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyk7mCGDPnYK5RnR13/XP9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## GAN 간단 설명\n","GAN은 기본적으로 두 개의 서로 다른 신경망의 적대적인 관계로 대립하며 서로의 성능을 점차 개선해 나가는 것 <br>\n","- 생성 모델 G : 데이터의 분포를 학습하는 모델 <br>\n","- 판별 모델 D : 이미지를 진짜(Train data) 또는 가짜(Generated data)인지 분류하는 모델 <br>\n","- 진짜 간단히 말하면, 경찰과 도둑 <br>\n","- MNIST로 구현 예정"],"metadata":{"id":"AabgQGjnt5qB"}},{"cell_type":"markdown","source":["## Library"],"metadata":{"id":"lnGfEyt-tSzM"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"AkRt6K4fsraR","executionInfo":{"status":"ok","timestamp":1709109730664,"user_tz":-540,"elapsed":11572,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","from torch.nn.modules import loss\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"markdown","source":["## Discriminator"],"metadata":{"id":"yAv2_YJOuX1g"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","  def __init__(self, in_features):\n","    super().__init__()\n","    self.disc = nn.Sequential(\n","        nn.Linear(in_features, 128),\n","        nn.LeakyReLU(0.1),\n","        nn.Linear(128, 1),\n","        nn.Sigmoid(), # 0.5를 기준으로 classification\n","    )\n","\n","  def forward(self, x):\n","    return self.disc(x)"],"metadata":{"id":"FOxbTItLtyGt","executionInfo":{"status":"ok","timestamp":1709109730664,"user_tz":-540,"elapsed":20,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Generator"],"metadata":{"id":"NJWKLdN4u9Fz"}},{"cell_type":"code","source":["class Generator(nn.Module):\n","  def __init__(self, z_dim, img_dim):\n","    super().__init__()\n","    self.gen = nn.Sequential(\n","        nn.Linear(z_dim, 256),\n","        nn.LeakyReLU(0.1),\n","        nn.Linear(256, img_dim),\n","        nn.Tanh(),\n","    )\n","\n","  def forward(self, x):\n","    return self.gen(x)"],"metadata":{"id":"SGSAFzm2ue80","executionInfo":{"status":"ok","timestamp":1709109730665,"user_tz":-540,"elapsed":6,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameters"],"metadata":{"id":"mTlZtdM2vWYK"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","lr = 3e-4\n","z_dim = 64 # 784가 아닌 64인 이유?\n","image_dim = 28 * 28 * 1\n","batch_size = 32\n","num_epochs = 50"],"metadata":{"id":"sMCg0aqCvSxL","executionInfo":{"status":"ok","timestamp":1709109730665,"user_tz":-540,"elapsed":5,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["입력 벡터를 784로 하는 것이 아니라 64로 하는 이유는 <br>\n","1. 10종류의 숫자를 표시하는 것으로 MNIST데이터의 분포는 이것보다 낮은 차원으로 집약되어 있을 것이므로 입력차원을 낮게 하는 것 <br>\n","2. MNIST가 해상도가 커져도 집약된 정보는 변하지 않기 때문에 더 많은 차원의 벡터가 필요하지 않음"],"metadata":{"id":"xZ-g4ar0vz35"}},{"cell_type":"code","source":["disc = Discriminator(image_dim).to(device)\n","gen = Generator(z_dim, image_dim).to(device)\n","fixed_noise = torch.randn((batch_size, z_dim)).to(device) # noise를 만듦\n","transforms = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, ), (0.5, )), ]\n",")\n","dataset = datasets.MNIST(root = \"dataset/\", transform = transforms, download = True)\n","loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n","opt_disc = optim.Adam(disc.parameters(), lr = lr)\n","opt_gen = optim.Adam(gen.parameters(), lr = lr)\n","criterion = nn.BCELoss() # real/fake 구분하기 위함\n","\n","writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n","writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\n","# tensorboard 사용을 위해 SummaryWriter를 선언\n","\n","step = 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXufLvwxwh5t","executionInfo":{"status":"ok","timestamp":1709109732833,"user_tz":-540,"elapsed":2172,"user":{"displayName":"이진","userId":"07182137582732274273"}},"outputId":"377ea79e-6d44-4278-eb30-de19d93f2147"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 310611883.69it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 110323947.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 207186680.55it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 4378425.37it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","  for batch_idx, (real, _) in enumerate(loader):\n","    real = real.view(-1, 784).to(device)\n","    batch_size = real.shape[0]\n","\n","    # Train Discriminator : max log(D(x)) + log(1 - D(G(z)))\n","    noise = torch.randn(batch_size, z_dim).to(device)\n","    fake = gen(noise)\n","    disc_real = disc(real).view(-1)\n","    lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n","    disc_fake = disc(fake).view(-1)\n","    lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","    lossD = (lossD_real + lossD_fake) / 2\n","    disc.zero_grad()\n","    lossD.backward(retain_graph = True)\n","    opt_disc.step()\n","\n","    # Train Generator : min log(1 - D(G(z))) <-> max log(D(G(z)))\n","    # 생성자를 훈련시킬 때 그레디언트가 세츄레이션되지 않는 최대화 방법 -> 학습이 더 안정적으로 이루어짐\n","    output = disc(fake).view(-1)\n","    lossG = criterion(output, torch.ones_like(output))\n","    gen.zero_grad()\n","    lossG.backward()\n","    opt_gen.step()\n","\n","    if batch_idx == 0:\n","      print(\n","          f'Epoch [{epoch} / {num_epochs}], Loss D : {lossD:.4f}, Loss G : {lossG:.4f}'\n","      )\n","\n","      with torch.no_grad():\n","        fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n","        data = real.reshape(-1, 1, 28, 28)\n","        img_grid_fake = torchvision.utils.make_grid(fake, normalize = True)\n","        img_grid_real = torchvision.utils.make_grid(data, normalize = True)\n","\n","        writer_fake.add_image('MNIST Fake Image', img_grid_fake, global_step = step)\n","        writer_real.add_image('MNIST Real Image', img_grid_real, global_step = step)\n","        step += 1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77wn76pFxhQk","executionInfo":{"status":"ok","timestamp":1709110716787,"user_tz":-540,"elapsed":983958,"user":{"displayName":"이진","userId":"07182137582732274273"}},"outputId":"0c9e5351-4cd2-467a-90d7-3f65ec51e1ee"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [0 / 50], Loss D : 0.6289, Loss G : 0.6685\n","Epoch [1 / 50], Loss D : 0.6519, Loss G : 0.9258\n","Epoch [2 / 50], Loss D : 0.3328, Loss G : 1.3609\n","Epoch [3 / 50], Loss D : 0.8028, Loss G : 0.5892\n","Epoch [4 / 50], Loss D : 0.5987, Loss G : 1.1845\n","Epoch [5 / 50], Loss D : 0.4644, Loss G : 1.1955\n","Epoch [6 / 50], Loss D : 1.1846, Loss G : 0.5425\n","Epoch [7 / 50], Loss D : 0.4152, Loss G : 1.3380\n","Epoch [8 / 50], Loss D : 0.7330, Loss G : 1.0478\n","Epoch [9 / 50], Loss D : 0.5563, Loss G : 1.0605\n","Epoch [10 / 50], Loss D : 0.5873, Loss G : 1.1433\n","Epoch [11 / 50], Loss D : 0.5487, Loss G : 1.3203\n","Epoch [12 / 50], Loss D : 0.7453, Loss G : 0.7413\n","Epoch [13 / 50], Loss D : 0.5126, Loss G : 1.0858\n","Epoch [14 / 50], Loss D : 0.5114, Loss G : 1.1865\n","Epoch [15 / 50], Loss D : 0.5785, Loss G : 0.8795\n","Epoch [16 / 50], Loss D : 0.6545, Loss G : 1.0566\n","Epoch [17 / 50], Loss D : 0.6320, Loss G : 1.2448\n","Epoch [18 / 50], Loss D : 0.5495, Loss G : 1.1825\n","Epoch [19 / 50], Loss D : 0.8595, Loss G : 0.8963\n","Epoch [20 / 50], Loss D : 0.5287, Loss G : 1.0239\n","Epoch [21 / 50], Loss D : 0.5755, Loss G : 1.4159\n","Epoch [22 / 50], Loss D : 0.6948, Loss G : 1.3472\n","Epoch [23 / 50], Loss D : 0.5853, Loss G : 1.1355\n","Epoch [24 / 50], Loss D : 0.6481, Loss G : 1.0412\n","Epoch [25 / 50], Loss D : 0.6826, Loss G : 0.9620\n","Epoch [26 / 50], Loss D : 0.6520, Loss G : 0.9165\n","Epoch [27 / 50], Loss D : 0.6216, Loss G : 0.9537\n","Epoch [28 / 50], Loss D : 0.6701, Loss G : 0.9343\n","Epoch [29 / 50], Loss D : 0.6357, Loss G : 1.1088\n","Epoch [30 / 50], Loss D : 0.4567, Loss G : 1.1756\n","Epoch [31 / 50], Loss D : 0.6800, Loss G : 1.0690\n","Epoch [32 / 50], Loss D : 0.5898, Loss G : 1.0617\n","Epoch [33 / 50], Loss D : 0.6689, Loss G : 0.9085\n","Epoch [34 / 50], Loss D : 0.7118, Loss G : 0.8200\n","Epoch [35 / 50], Loss D : 0.4994, Loss G : 1.2162\n","Epoch [36 / 50], Loss D : 0.5777, Loss G : 1.0859\n","Epoch [37 / 50], Loss D : 0.6646, Loss G : 1.1395\n","Epoch [38 / 50], Loss D : 0.5891, Loss G : 0.9795\n","Epoch [39 / 50], Loss D : 0.6049, Loss G : 0.9733\n","Epoch [40 / 50], Loss D : 0.7971, Loss G : 0.8371\n","Epoch [41 / 50], Loss D : 0.7224, Loss G : 0.8885\n","Epoch [42 / 50], Loss D : 0.5879, Loss G : 1.1458\n","Epoch [43 / 50], Loss D : 0.6236, Loss G : 0.9289\n","Epoch [44 / 50], Loss D : 0.8168, Loss G : 0.7679\n","Epoch [45 / 50], Loss D : 0.6644, Loss G : 0.9820\n","Epoch [46 / 50], Loss D : 0.7076, Loss G : 0.9790\n","Epoch [47 / 50], Loss D : 0.6322, Loss G : 0.9104\n","Epoch [48 / 50], Loss D : 0.6996, Loss G : 0.8384\n","Epoch [49 / 50], Loss D : 0.6181, Loss G : 1.0155\n"]}]},{"cell_type":"markdown","source":["Discriminator의 목표는 <br>\n","1. epoch을 돌면서 noise를 만들고 이미지 생성(fake) <br>\n","2. lossD_real = criterion(disc_real, torch.ones_like(disc_real)) -> 진짜 이미지에 대한 loss <br>\n","lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake)) -> 가짜 이미지에 대한 로스를 구해 <br>\n","평균을 구하고 backward 해줌 <br>\n","\n","Generator의 목표는 <br>\n","1. lossG를 구하고 backward"],"metadata":{"id":"buFmyIbx3cf-"}}]}
{"cells":[{"cell_type":"markdown","metadata":{"id":"Xkdt4Yi7dqGQ"},"source":["# Bidirectional Encoder Representations from Transformers\n","### 기존 GPT1의 한계점 : 왼쪽에서 오른쪽으로 단방향 처리는 문장 이해에 있어 약점이며 <br> 한 번 학습시키는데 엄청난 시간이 필요함\n","### BERT는\n","1. 양방향으로 이해해서 숫자의 형태로 바꿔주는 형태\n","2. 동일한 문장 그대로 학습하되 가려진 문장을 예측하도록 함 (masked token)\n","3. 한 문장말고 질의 및  응답같은 두 문장도 받을 수 있음 (양쪽 방향으로 처리하기에)\n","4. 문장 간의 상관관계도 파악이 가능하여 문장 주제 찾기 또는 분류도 가능함\n","5. Transformer의 Encoder 구조를 중점적으로 사용한 모델로 decoder를 사용하지 않고 encoder를 학습시킨 후(pre-training)<br> 특정 task의 fine-tuning을 활용하여 결과물을 얻는 방법으로 사용 됨\n","6. self attention layer를 여러 개 사용하여 문장에 포함되어 있는 token 사이의 의미 관계를 파악함"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5258,"status":"ok","timestamp":1712810836928,"user":{"displayName":"이진","userId":"07182137582732274273"},"user_tz":-540},"id":"nhTMMlxzc7Rs"},"outputs":[],"source":["import math\n","import re\n","from random import *\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Ky_OEuNexlA"},"outputs":[],"source":["# sample IsNext and NotNext to be same in small batch size\n","def make_batch():\n","    batch = []\n","    positive = negative = 0\n","    while positive != batch_size/2 or negative != batch_size/2:\n","        tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences)) # 문장 길이 범위내 랜덤 index 설정\n","        tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index] # 입력 문장의 token 중 index로 뽑아내기\n","        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']] # word_dict = PAD + CLS + SEP +  MASK + token\n","        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1) # 0 or1\n","        # token_a : CLS + tokens_a + SEP\n","        # token_b : tokens_b + SEP\n","\n","        # MASK LM\n","        # The training data generator chooses 15% of the token positions at random for prediction\n","        # 훈련 데이터 생성기는 예측을 위해 토큰 위치의 15%를 무작위로 선택합니다\n","        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 전체 중 15%만 맞추겠다\n","        cand_maked_pos = [i for i, token in enumerate(input_ids)\n","                          if token != word_dict['[CLS]'] and token != word_dict['[SEP]']] # input_ids 중 CLS와 SEP token이 아닌 token의 index\n","        shuffle(cand_maked_pos) # shuffle -> 뒤에 랜덤한 15%를 mask하기 위해 사전에 shuffle\n","        masked_tokens, masked_pos = [], []\n","        for pos in cand_maked_pos[:n_pred]: # 15%의 mask 중 -> 사전에 shuffle을 했기 때문에 [:n_pred] = 15% random 추출\n","            masked_pos.append(pos) # masking 할 token의 index\n","            masked_tokens.append(input_ids[pos]) # masking 할 token\n","            if random() < 0.8:  # 80%\n","                input_ids[pos] = word_dict['[MASK]'] # make mask\n","            elif random() < 0.5:  # 10%\n","                index = randint(0, vocab_size - 1) # random index in vocabulary\n","                input_ids[pos] = word_dict[number_dict[index]] # replace\n","\n","        # Zero Paddings -> max_len 사이즈로 zero_padding\n","        n_pad = maxlen - len(input_ids)\n","        input_ids.extend([0] * n_pad)\n","        segment_ids.extend([0] * n_pad)\n","\n","        # Zero Padding (100% - 15%) tokens -> max_pred size 만큼 mask_tokens을 zero_padding\n","        if max_pred > n_pred:\n","            n_pad = max_pred - n_pred\n","            masked_tokens.extend([0] * n_pad)\n","            masked_pos.extend([0] * n_pad)\n","\n","        if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2: # 위에서 랜덤하게 뽑은 두 문장이 연결되는 문장이고 positive가 batch_size/2라면\n","            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n","            positive += 1\n","        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2: # 두 문장이 연결되는 문장이 아니라면\n","            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n","            negative += 1\n","    return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPY3fuaWhTTW"},"outputs":[],"source":["def get_attn_pad_mask(seq_q, seq_k): # Attention을 구할 때 Padding 부분을 제외하기 위한 Mask\n","                                     # Padding = False, Tokens = True\n","    batch_size, len_q = seq_q.size() \n","    batch_size, len_k = seq_k.size()\n","    # eq(zero) is PAD token\n","    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n","    \n","    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_ids, segment_ids, masked_tokens, masked_pos, isNest = map(torch.LognTensor, zip(*batch))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["get_attn_pad_mask(input_ids, input_ids)[0][0] # True = 14, False(zzero padding) = 18"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gelu(x):\n","    \"Implementation of the gelu activation function by Hugging Face\"\n","    return x * 0.5 * (1.0 * torch.erf(x / math.sqrt(2.0)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Embedding(nn.Module):\n","    def __init__(self):\n","        super(Embedding, self).__init__()\n","        self.tok_embed = nn.Embedding(vocab_size, d_model) # token 값 자체 embedding\n","        self.pos_embed = nn.Embedding(maxlen, d_model) # token 고유 위치 값 embedding\n","        self.seg_embed = nn.Embedding(n_segments, d_model) # token이 어느 문장에 있었는 지에 대한 정보값 embedding\n","        self.norm = nn.LayerNorm(d_model)\n","\n","    def forward(self, x, seg):\n","        seq_len = x.sie(1) # padding을 포함한 문장의 길이 = max_len\n","        pos = torch.arange(seq_len, dtype = torch.long) # np.range와 동일 -> tensor화\n","        pos = pos.unsqueeze(0).expand_as(x)\n","        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n","\n","        return self.norm(embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOVitsSlydneDL+wZyy+p0i","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
